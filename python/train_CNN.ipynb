{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning using Keras\n",
    "In this notebook I will train a dog breed classifier using Keras and transfer learning techniques.  In total there ae 20K images from 119 dog breeds.  The steps in the notebook are:\n",
    " * Preprocess images: normalization, uniform scaling\n",
    " * Train the classifier\n",
    " * Evaluate the model and Validation\n",
    " * Improvements using Data Augmentation to help low stat classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "%matplotlib inline\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as py\n",
    "import operator, re, progressbar, sys\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import pickle, logging\n",
    "from skimage import color, exposure, transform, io\n",
    "from time import time\n",
    "import codecs, glob\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.engine.topology import Input\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "# My modules\n",
    "sys.path.insert(0,\"/Users/HAL3000/Dropbox/coding/my_modules/\")\n",
    "import keras_modules as my_keras_modules\n",
    "import misc_modules as misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "root_dir = '/Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images/'\n",
    "train_data_dir = root_dir+'/train/'\n",
    "test_data_dir  = root_dir+'/test/'\n",
    "\n",
    "# Dataset Constants\n",
    "NUM_CLASSES = 120\n",
    "IMG_SIZE = 48\n",
    "\n",
    "# Network Inputs\n",
    "#nb_train_samples = 4125\n",
    "#nb_validation_samples = 466 \n",
    "k.set_image_dim_ordering('tf')\n",
    "batch_size = 120\n",
    "epochs = 1\n",
    "\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "print(train_labels[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data\n",
    "Images vary in size and brightness.  Let's crop, scale, normalizr, and grey each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    \n",
    "    # Histogram normalization in v channel\n",
    "    # This normalizes the intensity , but leaves color alone\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central square crop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0] // 2, img.shape[1] // 2\n",
    "    img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,\n",
    "              centre[1] - min_side // 2:centre[1] + min_side // 2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img, -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will get each class with its label from the path and store into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class(img_path):     \n",
    "    '''Returns class labels as ints from dir names'''\n",
    "    temp = img_path.split('/')[-2]\n",
    "    #print('Saving Class Label:',int(re.sub('[^0-9]','', temp) )\n",
    "    return int(re.sub('[^0-9]','', temp))\n",
    "\n",
    "train_imgs   = []\n",
    "train_labels = []\n",
    "test_imgs    = []\n",
    "tets_labels  = []\n",
    "\n",
    "\n",
    "def process_all_images():\n",
    "    ''' Creates numpy arrays of image data and class labels\n",
    "    '''\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*/*.jpg'))\n",
    "    train_path = glob.glob(os.path.join(train_data_dir, '*/*.jpg'))\n",
    "    test_path  = glob.glob(os.path.join(test_data_dir, '*/*.jpg'))\n",
    "    np.random.shuffle(all_img_paths)\n",
    "\n",
    "    print('Train Path:',train_path)    \n",
    "    print('Test Path:',train_path)    \n",
    "    \n",
    "    for i,img_path in enumerate(train_path):\n",
    "        #if i == 2: break\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        if i%100==0:\n",
    "            print('---> Processing Image:',img_path)\n",
    "            print('Saving Class Label:', label)\n",
    "        train_imgs.append(img)\n",
    "        train_labels.append(label)      \n",
    "            \n",
    "    for i,img_path in enumerate(test_path):\n",
    "        #if i == 2: break\n",
    "        img = preprocess_img(io.imread(img_path))\n",
    "        label = get_class(img_path)\n",
    "        if i%100==0:\n",
    "            print('---> Processing Image:',img_path)\n",
    "            print('Saving Class Label:', label)\n",
    "        test_imgs.append(img)\n",
    "        test_labels.append(label)     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/30-Norwich_terrier/n02094258_3165.jpg\n",
      "Saving Class Label: 30\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/30-Norwich_terrier/n02094258_312.jpg\n",
      "Saving Class Label: 30\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/77-English_setter/n02100735_634.jpg\n",
      "Saving Class Label: 77\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/91-Samoyed/n02111889_5267.jpg\n",
      "Saving Class Label: 91\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/112-French_bulldog/n02108915_311.jpg\n",
      "Saving Class Label: 112\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/112-French_bulldog/n02108915_350.jpg\n",
      "Saving Class Label: 112\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/48-redbone/n02090379_1799.jpg\n",
      "Saving Class Label: 48\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/70-Scotch_terrier/n02097298_10965.jpg\n",
      "Saving Class Label: 70\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/111-curly-coated_retriever/n02099429_1433.jpg\n",
      "Saving Class Label: 111\n",
      "---> Processing Image: /Users/HAL3000/Dropbox/coding/Insight/Tinder/data/dog_breeds/Images//train/12-standard_poodle/n02113799_923.jpg\n",
      "Saving Class Label: 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f410aa190191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_all_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d2b417358711>\u001b[0m in \u001b[0;36mprocess_all_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#if i == 2: break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-7c54e4949359>\u001b[0m in \u001b[0;36mpreprocess_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2hsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexposure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalize_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhsv2rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# central square crop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mhsv2rgb\u001b[0;34m(hsv)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     out = np.choose(hi, [np.dstack((v, t, p)),\n\u001b[0;32m--> 344\u001b[0;31m                          \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                          \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                          \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_replace_zero_by_x_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#process_all_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if numpy arrays already exits\n",
    "if not os.path.exists('weights/x_train.npz'):\n",
    "    print(labels,NUM_CLASSES)\n",
    "\n",
    "    # Now make the x,y train arrays and save\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    \n",
    "    # Make one hot targets\n",
    "    #Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "    Y = to_categorical(labels)\n",
    "    \n",
    "    # save the train features and labels    \n",
    "    np.savez(\"weights/x_train\", X)\n",
    "    np.savez(\"weights/y_train\", Y)\n",
    "else:\n",
    "    x_train = np.load(\"weights/x_train.npz\")['arr_0']\n",
    "    y_train = np.load(\"weights/y_train.npz\")['arr_0']\n",
    "    \n",
    "# Check the shapes\n",
    "print('X train shape:', x_train.shape)\n",
    "print('Y train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the frozen model and my fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape = (IMG_SIZE, IMG_SIZE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing all but final two layers\n",
    "for layer in model.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(150, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(150, activation=\"relu\")(x)\n",
    "predictions = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", \n",
    "                    optimizer = optimizers.SGD(lr=0.01, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14458 images belonging to 122 classes.\n",
      "Found 6122 images belonging to 122 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize test and training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (IMG_SIZE, IMG_SIZE),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "#horizontal_flip = True,\n",
    "#fill_mode = \"nearest\",\n",
    "#zoom_range = 0.3,\n",
    "#width_shift_range = 0.3,\n",
    "#height_shift_range=0.3,\n",
    "#rotation_range=30\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "test_data_dir,\n",
    "target_size = (IMG_SIZE, IMG_SIZE),\n",
    "batch_size=batch_size,\n",
    "class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save our model using specified conditions\n",
    "checkpoint = ModelCheckpoint(\"vgg16_12.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "# Re-train our layers\n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = 14458,\n",
    "epochs = epochs,\n",
    "validation_data = test_generator,\n",
    "nb_val_samples = 6122,\n",
    "callbacks = [checkpoint, early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
